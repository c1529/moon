今天学习了好多python爬虫的东西
通用爬虫、聚焦爬虫、增量式爬虫
在要爬虫的网站后面加‘robots.txt’可以查看爬取的网站的那些信息可以合法爬取（君子协议）
get和post请求   明天了解
了解了持久化储存（将数据保存到本地）
   一、get请求
 将数据保存成html形式
 url='网站'
   response=requests.get(url，headers=headers)  
 可以实现动态搜索：
   首先定义一个字典  dict={'query':param}    param为输入的变量   
   response=requests.get(url，params=dict,headers=headers)     params将字典接在url后面，即urlquery=param
     with open用法
         with open('保存的路径.html'，mode='r/w/a',encoding='utf-8') as f1:
          f1.write(response.text)
*****r：只读  用read()
*****w：只写 用write()            //会清除之前写的内容
*****a：追加内容 用write()        //会在已经写的内容基础上增加新的内容
####################################################
#搜狗动态搜索（用get请求）
import requests
url='https://www.sogou.com/web?'
headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}
aa=input('请输入：')
a={'query':aa}
b=requests.get(url,params=a,headers=headers)
filename=aa+'.html'
#print(filename)
with open(filename,'w',encoding='utf-8') as f1:
    f1.write(b.text)
########################################################
明天写post的内容和AJAX请求
AJAX请求可以理解为网页异步刷新，指在不刷新整个网页的前提下对网页进行局部刷新。
在xhr中的post类型请求中可以找到，格式为JSON类型
#########################################################
#破解百度翻译（post请求）
import requests
import json
url='https://fanyi.baidu.com/sug'
aa=input("请输入：")
data={'kw':aa}
headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}
a=requests.post(url,data=data,headers=headers)
b=a.json()
c=aa+'.json'
fp=open(c,'w',encoding='utf-8')     #fp-文件参数
json.dump(b,fp=fp,ensure_ascii=False)
#############################################################




















